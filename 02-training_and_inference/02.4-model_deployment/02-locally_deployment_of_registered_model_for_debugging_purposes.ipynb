{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locally Deployment of a Registered Model for Debugging Purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same code of the previous notebook is used here, except the deployment target (local Docker)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "from azureml.core.compute import AksCompute, ComputeTarget\n",
    "from azureml.core.webservice import Webservice, AksWebservice\n",
    "from azureml.core.model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.17.0\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "print(azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demo-ent-ws\n",
      "demo\n",
      "westeurope\n",
      "bcbf34a7-1936-4783-8840-8f324c37f354\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: aml-wrkshp-classif-empl-attrition\n",
      "Model description: Binary classification model for employees attrition\n",
      "Model version: 3\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "model = Model(ws, 'aml-wrkshp-classif-empl-attrition')\n",
    "\n",
    "print('Model name: ', model.name, '\\n', 'Model description: ', model.description, '\\n', 'Model version: ', model.version, sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'classif-empl-attrition.pkl'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the model locally in order to test the score.py script\n",
    "model.download(target_dir='.', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.externals import joblib\n",
    "import joblib\n",
    "\n",
    "from inference_schema.schema_decorators import input_schema, output_schema\n",
    "from inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\n",
    "from inference_schema.parameter_types.pandas_parameter_type import PandasParameterType\n",
    "\n",
    "\n",
    "input_sample = pd.DataFrame(data=[{'Age': 49, 'BusinessTravel': 'Travel_Rarely', 'DailyRate': 1098, 'Department': 'Research & Development', 'DistanceFromHome': 4, 'Education': 2, 'EducationField': 'Medical', 'EnvironmentSatisfaction': 4, 'Gender': 'Female', 'HourlyRate': 21, 'JobInvolvement': 3, 'JobLevel': 2, 'JobRole': 'Laboratory Technician', 'JobSatisfaction': 3, 'MaritalStatus': 'Single', 'MonthlyIncome': 711, 'MonthlyRate': 2124, 'NumCompaniesWorked': 8, 'OverTime': 1, 'PercentSalaryHike': 8, 'PerformanceRating': 4, 'RelationshipSatisfaction': 3, 'StockOptionLevel': 0, 'TotalWorkingYears': 2, 'TrainingTimesLastYear': 0, 'WorkLifeBalance': 3, 'YearsAtCompany': 2, 'YearsInCurrentRole': 1, 'YearsSinceLastPromotion': 0, 'YearsWithCurrManager': 1}])\n",
    "output_sample = np.array([0])\n",
    "\n",
    "\n",
    "def init():\n",
    "    # AZUREML_MODEL_DIR is an environment variable created during deployment. Join this path with the filename of the model file.\n",
    "    # It holds the path to the directory that contains the deployed model (./azureml-models/$MODEL_NAME/$VERSION).\n",
    "    # If there are multiple models, this value is the path to the directory containing all deployed models (./azureml-models).\n",
    "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'classif-empl-attrition.pkl')\n",
    "    \n",
    "    # Deserialize the model file back into a sklearn model\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "\n",
    "@input_schema('data', PandasParameterType(input_sample))\n",
    "@output_schema(NumpyParameterType(output_sample))\n",
    "def run(data):\n",
    "    try:\n",
    "        result = model.predict(data)\n",
    "        return json.dumps({\"result\": result.tolist()})\n",
    "    except Exception as e:\n",
    "        result = str(e)\n",
    "        return json.dumps({\"error\": result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from azureml.core.environment import Environment\n",
    "\n",
    "environment = Environment(\"LocalDeploy\")\n",
    "\n",
    "environment.python.conda_dependencies.add_conda_package(\"python=3.6.2\")\n",
    "environment.python.conda_dependencies.add_conda_package(\"pandas\")\n",
    "environment.python.conda_dependencies.add_conda_package(\"numpy\")\n",
    "\n",
    "environment.python.conda_dependencies.add_pip_package(\"azureml-core==1.17.0\")\n",
    "environment.python.conda_dependencies.add_pip_package(\"azureml-defaults==1.17.0\")\n",
    "environment.python.conda_dependencies.add_pip_package(\"sklearn-pandas\")\n",
    "environment.python.conda_dependencies.add_pip_package(\"inference-schema[numpy-support]\")\n",
    "environment.python.conda_dependencies.add_pip_package(\"joblib\")\n",
    "environment.python.conda_dependencies.add_pip_package(\"scikit-learn==0.22.2.post1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "inference_config = InferenceConfig(entry_script=\"score.py\",\n",
    "                                   environment=environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model aml-wrkshp-classif-empl-attrition:3 to /tmp/azureml_06aait_s/aml-wrkshp-classif-empl-attrition/3\n",
      "Generating Docker build context.\n",
      "Package creation Succeeded\n",
      "Logging into Docker registry demoentwsb5fa738e.azurecr.io\n",
      "Logging into Docker registry demoentwsb5fa738e.azurecr.io\n",
      "Building Docker image from Dockerfile...\n",
      "Step 1/5 : FROM demoentwsb5fa738e.azurecr.io/azureml/azureml_1a20c7e2547432c1a93b79d84147bb47\n",
      " ---> 7b22859be9d7\n",
      "Step 2/5 : COPY azureml-app /var/azureml-app\n",
      " ---> 7b000f2b3f7f\n",
      "Step 3/5 : RUN mkdir -p '/var/azureml-app' && echo eyJhY2NvdW50Q29udGV4dCI6eyJzdWJzY3JpcHRpb25JZCI6ImJjYmYzNGE3LTE5MzYtNDc4My04ODQwLThmMzI0YzM3ZjM1NCIsInJlc291cmNlR3JvdXBOYW1lIjoiZGVtbyIsImFjY291bnROYW1lIjoiZGVtby1lbnQtd3MiLCJ3b3Jrc3BhY2VJZCI6IjU5NTcyYTM0LThiNmItNDM0ZS04ODMwLTI0NDlhMzEzMjI0MCJ9LCJtb2RlbHMiOnt9LCJtb2RlbHNJbmZvIjp7fX0= | base64 --decode > /var/azureml-app/model_config_map.json\n",
      " ---> Running in 7ecc414515ac\n",
      " ---> d90a3f4e3f2a\n",
      "Step 4/5 : RUN mv '/var/azureml-app/tmpkx25s20o.py' /var/azureml-app/main.py\n",
      " ---> Running in 3aa5149978cd\n",
      " ---> 1035213703ea\n",
      "Step 5/5 : CMD [\"runsvdir\",\"/var/runit\"]\n",
      " ---> Running in 0c94ccdd0613\n",
      " ---> 44425770f1fe\n",
      "Successfully built 44425770f1fe\n",
      "Successfully tagged predict-attrition-test:latest\n",
      "Container (name:nostalgic_saha, id:3a08b19272d0be534723d2b74dbd828c00898f3ef5c1af1aa01b5964cfb4e95d) cannot be killed.\n",
      "Container has been successfully cleaned up.\n",
      "Image sha256:6af0728a323b8cefbeba451f0cf46c5de160048225cfe5ada4fac946e2a2044e successfully removed.\n",
      "Starting Docker container...\n",
      "Docker container running.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.webservice import LocalWebservice\n",
    "\n",
    "webservice_name = 'predict-attrition-test'\n",
    "\n",
    "# This is optional, if not provided Docker will choose a random unused port.\n",
    "deployment_config = LocalWebservice.deploy_configuration(port=6789)\n",
    "\n",
    "local_service = Model.deploy(ws, webservice_name, [model], inference_config, deployment_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking container health...\n",
      "Local webservice is running at http://localhost:6789\n"
     ]
    }
   ],
   "source": [
    "local_service.wait_for_deployment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local service port: running\n",
      "Local service port: 6789\n"
     ]
    }
   ],
   "source": [
    "print('Local service port: {}'.format(local_service.state))\n",
    "print('Local service port: {}'.format(local_service.port))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-12T10:20:55,611419780+00:00 - rsyslog/run \n",
      "2020-11-12T10:20:55,613485559+00:00 - iot-server/run \n",
      "2020-11-12T10:20:55,615089598+00:00 - gunicorn/run \n",
      "2020-11-12T10:20:55,623347515+00:00 - nginx/run \n",
      "/usr/sbin/nginx: /azureml-envs/azureml_b417035e27d8ada91933498a4a62fd54/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_b417035e27d8ada91933498a4a62fd54/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_b417035e27d8ada91933498a4a62fd54/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_b417035e27d8ada91933498a4a62fd54/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_b417035e27d8ada91933498a4a62fd54/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2020-11-12T10:20:55,698124407+00:00 - iot-server/finish 1 0\n",
      "2020-11-12T10:20:55,699364614+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (10)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 41\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Initializing logger\n",
      "2020-11-12 10:20:56,758 | root | INFO | Starting up app insights client\n",
      "Starting up app insights client\n",
      "2020-11-12 10:20:56,758 | root | INFO | Starting up request id generator\n",
      "Starting up request id generator\n",
      "2020-11-12 10:20:56,758 | root | INFO | Starting up app insight hooks\n",
      "Starting up app insight hooks\n",
      "2020-11-12 10:20:56,758 | root | INFO | Invoking user's init function\n",
      "Invoking user's init function\n",
      "2020-11-12 10:20:56,786 | root | INFO | Users's init has completed successfully\n",
      "Users's init has completed successfully\n",
      "/azureml-envs/azureml_b417035e27d8ada91933498a4a62fd54/lib/python3.6/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator SimpleImputer from version 0.22.2.post1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/azureml-envs/azureml_b417035e27d8ada91933498a4a62fd54/lib/python3.6/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator StandardScaler from version 0.22.2.post1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/azureml-envs/azureml_b417035e27d8ada91933498a4a62fd54/lib/python3.6/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator Pipeline from version 0.22.2.post1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/azureml-envs/azureml_b417035e27d8ada91933498a4a62fd54/lib/python3.6/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator OneHotEncoder from version 0.22.2.post1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/azureml-envs/azureml_b417035e27d8ada91933498a4a62fd54/lib/python3.6/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.22.2.post1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "2020-11-12 10:20:56,787 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
      "Skipping middleware: dbg_model_info as it's not enabled.\n",
      "2020-11-12 10:20:56,788 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "2020-11-12 10:20:56,789 | root | INFO | Scoring timeout setting is not found. Use default timeout: 3600000 ms\n",
      "Scoring timeout setting is not found. Use default timeout: 3600000 ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(local_service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
